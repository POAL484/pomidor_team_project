{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Windows.old\\Users\\pbrag\\AppData\\Local\\Programs\\Python\\Python311\\pomidor_team_project\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import urllib.request\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X.\\r BOOK XXI.\\r BOOK XXII.\\r BOOK XXIII.\\r BOOK XXIV.\\r\\r CONCLUDING NOTE.\\r\\r\\r\\r\\rIllustrations\\r\\r HOMER INVOKING THE MUSE\\r MARS\\r MINERVA REPRESSING THE FURY OF ACHILLES\\r THE DEPARTURE OF BRISEIS FROM THE TENT'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.gutenberg.org/cache/epub/6130/pg6130.txt\"\n",
    "file = urllib.request.urlopen(url)\n",
    "text = [line.decode('utf-8') for line in file]\n",
    "text = ''.join(text)\n",
    "text = re.sub(' +',' ',text)\n",
    "text = re.sub(r'[^A-Za-z.,!\\r ]+', '', text)\n",
    "text = text[1150:]\n",
    "text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\r, ,!,,,.,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "\",\".join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\r = 0',\n",
       " '  = 1',\n",
       " '! = 2',\n",
       " ', = 3',\n",
       " '. = 4',\n",
       " 'A = 5',\n",
       " 'B = 6',\n",
       " 'C = 7',\n",
       " 'D = 8',\n",
       " 'E = 9',\n",
       " 'F = 10',\n",
       " 'G = 11',\n",
       " 'H = 12',\n",
       " 'I = 13',\n",
       " 'J = 14',\n",
       " 'K = 15',\n",
       " 'L = 16',\n",
       " 'M = 17',\n",
       " 'N = 18',\n",
       " 'O = 19']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "[f\"{char} = {i}\" for char, i in zip(char2idx, range(20))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X', '.', '\\r', ' ', 'B']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "[idx2char[i.numpy()] for i in char_dataset.take(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'X.\\\\r BOOK XXI.\\\\r BOOK XXII.\\\\r BOOK XXIII.\\\\r BOOK XXIV.\\\\r\\\\r CONCLUDING NOTE.\\\\r\\\\r\\\\r\\\\r\\\\rIllustrations\\\\r\\\\r HOMER INVOK'\",\n",
       " \"'ING THE MUSE\\\\r MARS\\\\r MINERVA REPRESSING THE FURY OF ACHILLES\\\\r THE DEPARTURE OF BRISEIS FROM THE TENT O'\",\n",
       " \"'F ACHILLES\\\\r THETIS CALLING BRIAREUS TO THE ASSISTANCE OF JUPITER\\\\r THETIS ENTREATING JUPITER TO HONOUR'\",\n",
       " \"' ACHILLES\\\\r VULCAN\\\\r JUPITER\\\\r THE APOTHEOSIS OF HOMER\\\\r JUPITER SENDING THE EVIL DREAM TO AGAMEMNON\\\\r NEP'\",\n",
       " \"'TUNE\\\\r VENUS, DISGUISED, INVITING HELEN TO THE CHAMBER OF PARIS\\\\r VENUS PRESENTING HELEN TO PARIS\\\\r VENU'\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "[repr(''.join(idx2char[item.numpy()])) for item in sequences.take(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.autograph.experimental.do_not_convert\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'X.\\r BOOK XXI.\\r BOOK XXII.\\r BOOK XXIII.\\r BOOK XXIV.\\r\\r CONCLUDING NOTE.\\r\\r\\r\\r\\rIllustrations\\r\\r HOMER INVO'\n",
      "Target data: '.\\r BOOK XXI.\\r BOOK XXII.\\r BOOK XXIII.\\r BOOK XXIV.\\r\\r CONCLUDING NOTE.\\r\\r\\r\\r\\rIllustrations\\r\\r HOMER INVOK'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 28 ('X')\n",
      "  expected output: 4 ('.')\n",
      "Step    1\n",
      "  input: 4 ('.')\n",
      "  expected output: 0 ('\\r')\n",
      "Step    2\n",
      "  input: 0 ('\\r')\n",
      "  expected output: 1 (' ')\n",
      "Step    3\n",
      "  input: 1 (' ')\n",
      "  expected output: 6 ('B')\n",
      "Step    4\n",
      "  input: 6 ('B')\n",
      "  expected output: 19 ('O')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "rnn_units_2 = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Windows.old\\Users\\pbrag\\AppData\\Local\\Programs\\Python\\Python311\\pomidor_team_project\\venv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (128, None, 256)          14592     \n",
      "                                                                 \n",
      " gru (GRU)                   (128, None, 1024)         3938304   \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (128, None, 512)          2362368   \n",
      "                                                                 \n",
      " dense (Dense)               (128, None, 57)           29241     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6344505 (24.20 MB)\n",
      "Trainable params: 6344505 (24.20 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                            batch_input_shape=[BATCH_SIZE, None]),\n",
    "  tf.keras.layers.GRU(rnn_units,\n",
    "                      return_sequences=True,\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform'), \n",
    "  tf.keras.layers.GRU(rnn_units_2,\n",
    "                      return_sequences=True,\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform'),  \n",
    "  tf.keras.layers.Dense(vocab_size)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Windows.old\\Users\\pbrag\\AppData\\Local\\Programs\\Python\\Python311\\pomidor_team_project\\venv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Windows.old\\Users\\pbrag\\AppData\\Local\\Programs\\Python\\Python311\\pomidor_team_project\\venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "84/84 [==============================] - 270s 3s/step - loss: 2.6677\n",
      "Epoch 2/200\n",
      "84/84 [==============================] - ETA: 0s - loss: 2.0100"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xcd in position 327: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Windows.old\\Users\\pbrag\\AppData\\Local\\Programs\\Python\\Python311\\pomidor_team_project\\NeuralPOAL\\tensorflow_NLP.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Windows.old/Users/pbrag/AppData/Local/Programs/Python/Python311/pomidor_team_project/NeuralPOAL/tensorflow_NLP.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(dataset, epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[checkpoint_callback])\n",
      "File \u001b[1;32mc:\\Windows.old\\Users\\pbrag\\AppData\\Local\\Programs\\Python\\Python311\\pomidor_team_project\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Windows.old\\Users\\pbrag\\AppData\\Local\\Programs\\Python\\Python311\\pomidor_team_project\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xcd in position 327: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=200, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, temp, gen_chars):     \n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)  \n",
    "  text_generated = []\n",
    "  model.reset_states()\n",
    "  for i in range(gen_chars):\n",
    "    predictions = model(input_eval)      \n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "    predictions = predictions / temp\n",
    "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "    input_eval = tf.expand_dims([predicted_id], 0)\n",
    "    text_generated.append(idx2char[predicted_id])  \n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_25 (Embedding)    (1, None, 256)            14592     \n",
      "                                                                 \n",
      " gru_50 (GRU)                (1, None, 1024)           3938304   \n",
      "                                                                 \n",
      " gru_51 (GRU)                (1, None, 512)            2362368   \n",
      "                                                                 \n",
      " dense_25 (Dense)            (1, None, 57)             29241     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,344,505\n",
      "Trainable params: 6,344,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                            batch_input_shape=[1, None]),\n",
    "  tf.keras.layers.GRU(rnn_units,\n",
    "                      return_sequences=True,\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform'),\n",
    "  tf.keras.layers.GRU(rnn_units_2,\n",
    "                      return_sequences=True,\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform'), \n",
    "  tf.keras.layers.Dense(vocab_size)\n",
    "])\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                            batch_input_shape=[1, None]),\n",
    "  tf.keras.layers.GRU(rnn_units,\n",
    "                      return_sequences=True,\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform'),\n",
    "  tf.keras.layers.GRU(rnn_units_2,\n",
    "                      return_sequences=True,\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform'), \n",
    "  tf.keras.layers.Dense(vocab_size)\n",
    "])\n",
    "model.summary()\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Throgh death, eternal shame.\\r\\rHis generous steeds he grinds his royal guest\\rNo less the rage of all their hosts.\\r\\rWhat godlike coursers fed his eyes\\rOn the cold towers of swiftness in the race.\\rA wellfed ox the l'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, u\"Throgh death\", 1.0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_50_layer_call_fn, gru_cell_50_layer_call_and_return_conditional_losses, gru_cell_51_layer_call_fn, gru_cell_51_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: NLP_gen_illiad_200/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: NLP_gen_illiad_200/assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f1e8cc92f80> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f1e8cf42f80> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# model.save(\"NLP_gen_illiad_200\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
