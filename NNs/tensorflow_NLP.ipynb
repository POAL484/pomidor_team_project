{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\olymp\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import urllib.request\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets_analizer import DataSetsAnalizer\n",
    "\n",
    "DSA = DataSetsAnalizer()\n",
    "\n",
    "text = str(DSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n, ,!,\",#,$,%,&,\\',(,),*,+,,,-,.,/,0,1,2,3,4,5,6,7,8,9,:,;,<,=,>,?,@,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,[,],^,_,`,a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,©,\\xad,°,Ё,А,Б,В,Г,Д,Е,Ж,З,И,Й,К,Л,М,Н,О,П,Р,С,Т,У,Ф,Х,Ц,Ч,Ш,Щ,Ъ,Ы,Ь,Э,Ю,Я,а,б,в,г,д,е,ж,з,и,й,к,л,м,н,о,п,р,с,т,у,ф,х,ц,ч,ш,щ,ъ,ы,ь,э,ю,я,ё,’,“,”,€,№,�'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "\",\".join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n = 0',\n",
       " '  = 1',\n",
       " '! = 2',\n",
       " '\" = 3',\n",
       " '# = 4',\n",
       " '$ = 5',\n",
       " '% = 6',\n",
       " '& = 7',\n",
       " \"' = 8\",\n",
       " '( = 9',\n",
       " ') = 10',\n",
       " '* = 11',\n",
       " '+ = 12',\n",
       " ', = 13',\n",
       " '- = 14',\n",
       " '. = 15',\n",
       " '/ = 16',\n",
       " '0 = 17',\n",
       " '1 = 18',\n",
       " '2 = 19']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "[f\"{char} = {i}\" for char, i in zip(char2idx, range(20))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ц', 'Б', ' ', 'Р', 'Ф']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "[idx2char[i.numpy()] for i in char_dataset.take(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'ЦБ РФ объявил о переходе от плавающего курса рубля к тонущему.\\\\n- Ваши политические взгляды?- Самец.\\\\nЯ'\",\n",
       " \"' ужинать хочу. Куда враги все подевались?\\\\nПо утрам бегают те, кто ночью бездельничал.\\\\n- Кого ты боишь'\",\n",
       " \"'ся больше всего на свете?- Темноты и стоматологов.- Ну, стоматологов - ясно, а темноты-то почему?- А '\",\n",
       " \"'кто знает, сколько их там, в темноте-то стоматологов!\\\\nИдет первая русско-украинская война в интернете'\",\n",
       " \"'. Убитых нет, но много раненых в голову.\\\\nПочему россияне не боятся антироссийских санкций? Людей, кот'\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "[repr(''.join(idx2char[item.numpy()])) for item in sequences.take(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.autograph.experimental.do_not_convert\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'ЦБ РФ объявил о переходе от плавающего курса рубля к тонущему.\\n- Ваши политические взгляды?- Самец.\\n'\n",
      "Target data: 'Б РФ объявил о переходе от плавающего курса рубля к тонущему.\\n- Ваши политические взгляды?- Самец.\\nЯ'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 117 ('Ц')\n",
      "  expected output: 96 ('Б')\n",
      "Step    1\n",
      "  input: 96 ('Б')\n",
      "  expected output: 1 (' ')\n",
      "Step    2\n",
      "  input: 1 (' ')\n",
      "  expected output: 111 ('Р')\n",
      "Step    3\n",
      "  input: 111 ('Р')\n",
      "  expected output: 115 ('Ф')\n",
      "Step    4\n",
      "  input: 115 ('Ф')\n",
      "  expected output: 1 (' ')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "rnn_units_2 = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\olymp\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (8096, None, 256)         42496     \n",
      "                                                                 \n",
      " gru (GRU)                   (8096, None, 1024)        3938304   \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (8096, None, 512)         2362368   \n",
      "                                                                 \n",
      " dense (Dense)               (8096, None, 166)         85158     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6428326 (24.52 MB)\n",
      "Trainable params: 6428326 (24.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                            batch_input_shape=[BATCH_SIZE, None]),\n",
    "  tf.keras.layers.GRU(rnn_units,\n",
    "                      return_sequences=True,\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform'), \n",
    "  tf.keras.layers.GRU(rnn_units_2,\n",
    "                      return_sequences=True,\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform'),  \n",
    "  tf.keras.layers.Dense(vocab_size)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\olymp\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\olymp\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=3, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Program Files\\Python311\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Program Files/Python311/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_string, temp, gen_chars):     \n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)  \n",
    "  text_generated = []\n",
    "  model.reset_states()\n",
    "  for i in range(gen_chars):\n",
    "    predictions = model(input_eval)      \n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "    predictions = predictions / temp\n",
    "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "    input_eval = tf.expand_dims([predicted_id], 0)\n",
    "    text_generated.append(idx2char[predicted_id])  \n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Program Files\\Python311\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Program Files/Python311/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                            batch_input_shape=[1, None]),\n",
    "  tf.keras.layers.GRU(rnn_units,\n",
    "                      return_sequences=True,\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform'),\n",
    "  tf.keras.layers.GRU(rnn_units_2,\n",
    "                      return_sequences=True,\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform'), \n",
    "  tf.keras.layers.Dense(vocab_size)\n",
    "])\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                            batch_input_shape=[1, None]),\n",
    "  tf.keras.layers.GRU(rnn_units,\n",
    "                      return_sequences=True,\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform'),\n",
    "  tf.keras.layers.GRU(rnn_units_2,\n",
    "                      return_sequences=True,\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform'), \n",
    "  tf.keras.layers.Dense(vocab_size)\n",
    "])\n",
    "model.summary()\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Program Files\\Python311\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Program Files/Python311/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "generate_text(model, u\"Появился в зоне чёрни сталкер\", 1.0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Program Files\\Python311\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Program Files/Python311/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# model.save(\"NLP_gen_illiad_200\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
