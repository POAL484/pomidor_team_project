{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import urllib.request\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TER VII. A Mad TeaParty\\r CHAPTER VIII. The Queens CroquetGround\\r CHAPTER IX. The Mock Turtles Story\\r CHAPTER X. The Lobster Quadrille\\r CHAPTER XI. Who Stole the Tarts\\r CHAPTER XII. Alices Evidence\\r\\r\\r\\r'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.gutenberg.org/files/11/11-0.txt\"\n",
    "file = urllib.request.urlopen(url)\n",
    "text = [line.decode('utf-8') for line in file]\n",
    "text = ''.join(text)\n",
    "text = re.sub(' +',' ',text)\n",
    "text = re.sub(r'[^A-Za-z.,!\\r ]+', '', text)\n",
    "text = text[1150:]\n",
    "text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\r, ,!,,,.,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z,a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "\",\".join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\r = 0',\n",
       " '  = 1',\n",
       " '! = 2',\n",
       " ', = 3',\n",
       " '. = 4',\n",
       " 'A = 5',\n",
       " 'B = 6',\n",
       " 'C = 7',\n",
       " 'D = 8',\n",
       " 'E = 9',\n",
       " 'F = 10',\n",
       " 'G = 11',\n",
       " 'H = 12',\n",
       " 'I = 13',\n",
       " 'J = 14',\n",
       " 'K = 15',\n",
       " 'L = 16',\n",
       " 'M = 17',\n",
       " 'N = 18',\n",
       " 'O = 19']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "[f\"{char} = {i}\" for char, i in zip(char2idx, range(20))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T', 'E', 'R', ' ', 'V']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "[idx2char[i.numpy()] for i in char_dataset.take(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'TER VII. A Mad TeaParty\\\\r CHAPTER VIII. The Queens CroquetGround\\\\r CHAPTER IX. The Mock Turtles Story\\\\r '\",\n",
       " \"'CHAPTER X. The Lobster Quadrille\\\\r CHAPTER XI. Who Stole the Tarts\\\\r CHAPTER XII. Alices Evidence\\\\r\\\\r\\\\r\\\\r\\\\rC'\",\n",
       " \"'HAPTER I.\\\\rDown the RabbitHole\\\\r\\\\r\\\\rAlice was beginning to get very tired of sitting by her sister on the'\",\n",
       " \"'\\\\rbank, and of having nothing to do once or twice she had peeped into\\\\rthe book her sister was reading,'\",\n",
       " \"' but it had no pictures or\\\\rconversations in it, and what is the use of a book, thought Alice\\\\rwithout '\"]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "[repr(''.join(idx2char[item.numpy()])) for item in sequences.take(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.autograph.experimental.do_not_convert\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'TER VII. A Mad TeaParty\\r CHAPTER VIII. The Queens CroquetGround\\r CHAPTER IX. The Mock Turtles Story\\r'\n",
      "Target data: 'ER VII. A Mad TeaParty\\r CHAPTER VIII. The Queens CroquetGround\\r CHAPTER IX. The Mock Turtles Story\\r '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 24 ('T')\n",
      "  expected output: 9 ('E')\n",
      "Step    1\n",
      "  input: 9 ('E')\n",
      "  expected output: 22 ('R')\n",
      "Step    2\n",
      "  input: 22 ('R')\n",
      "  expected output: 1 (' ')\n",
      "Step    3\n",
      "  input: 1 (' ')\n",
      "  expected output: 26 ('V')\n",
      "Step    4\n",
      "  input: 26 ('V')\n",
      "  expected output: 13 ('I')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "rnn_units_2 = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.bias\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (64, None, 256)           14592     \n",
      "                                                                 \n",
      " gru_18 (GRU)                (64, None, 1024)          3938304   \n",
      "                                                                 \n",
      " gru_19 (GRU)                (64, None, 512)           2362368   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (64, None, 57)            29241     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,344,505\n",
      "Trainable params: 6,344,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                            batch_input_shape=[BATCH_SIZE, None]),\n",
    "  tf.keras.layers.GRU(rnn_units,\n",
    "                      return_sequences=True,\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform'), \n",
    "  tf.keras.layers.GRU(rnn_units_2,\n",
    "                      return_sequences=True,\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform'),  \n",
    "  tf.keras.layers.Dense(vocab_size)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "24/24 [==============================] - 24s 954ms/step - loss: 3.2620\n",
      "Epoch 2/50\n",
      "24/24 [==============================] - 23s 938ms/step - loss: 2.7040\n",
      "Epoch 3/50\n",
      "24/24 [==============================] - 23s 939ms/step - loss: 2.3630\n",
      "Epoch 4/50\n",
      "24/24 [==============================] - 23s 940ms/step - loss: 2.1917\n",
      "Epoch 5/50\n",
      "24/24 [==============================] - 23s 939ms/step - loss: 2.0469\n",
      "Epoch 6/50\n",
      "24/24 [==============================] - 23s 939ms/step - loss: 1.9155\n",
      "Epoch 7/50\n",
      "24/24 [==============================] - 23s 939ms/step - loss: 1.8009\n",
      "Epoch 8/50\n",
      "24/24 [==============================] - 23s 941ms/step - loss: 1.6919\n",
      "Epoch 9/50\n",
      "24/24 [==============================] - 23s 939ms/step - loss: 1.5983\n",
      "Epoch 10/50\n",
      "24/24 [==============================] - 23s 941ms/step - loss: 1.5063\n",
      "Epoch 11/50\n",
      "24/24 [==============================] - 23s 939ms/step - loss: 1.4248\n",
      "Epoch 12/50\n",
      "24/24 [==============================] - 23s 938ms/step - loss: 1.3498\n",
      "Epoch 13/50\n",
      "24/24 [==============================] - 23s 939ms/step - loss: 1.2731\n",
      "Epoch 14/50\n",
      "24/24 [==============================] - 23s 937ms/step - loss: 1.2036\n",
      "Epoch 15/50\n",
      "24/24 [==============================] - 23s 936ms/step - loss: 1.1378\n",
      "Epoch 16/50\n",
      "24/24 [==============================] - 23s 939ms/step - loss: 1.0659\n",
      "Epoch 17/50\n",
      "24/24 [==============================] - 22s 896ms/step - loss: 0.9933\n",
      "Epoch 18/50\n",
      "24/24 [==============================] - 21s 886ms/step - loss: 0.9233\n",
      "Epoch 19/50\n",
      "24/24 [==============================] - 21s 886ms/step - loss: 0.8486\n",
      "Epoch 20/50\n",
      "24/24 [==============================] - 21s 886ms/step - loss: 0.7742\n",
      "Epoch 21/50\n",
      "24/24 [==============================] - 22s 918ms/step - loss: 0.7042\n",
      "Epoch 22/50\n",
      "24/24 [==============================] - 22s 932ms/step - loss: 0.6312\n",
      "Epoch 23/50\n",
      "24/24 [==============================] - 23s 934ms/step - loss: 0.5657\n",
      "Epoch 24/50\n",
      "24/24 [==============================] - 23s 934ms/step - loss: 0.5059\n",
      "Epoch 25/50\n",
      "24/24 [==============================] - 23s 934ms/step - loss: 0.4570\n",
      "Epoch 26/50\n",
      "24/24 [==============================] - 23s 934ms/step - loss: 0.4119\n",
      "Epoch 27/50\n",
      "24/24 [==============================] - 23s 935ms/step - loss: 0.3731\n",
      "Epoch 28/50\n",
      "24/24 [==============================] - 23s 933ms/step - loss: 0.3429\n",
      "Epoch 29/50\n",
      "24/24 [==============================] - 23s 933ms/step - loss: 0.3163\n",
      "Epoch 30/50\n",
      "24/24 [==============================] - 23s 937ms/step - loss: 0.2940\n",
      "Epoch 31/50\n",
      "24/24 [==============================] - 23s 936ms/step - loss: 0.2755\n",
      "Epoch 32/50\n",
      "24/24 [==============================] - 23s 936ms/step - loss: 0.2607\n",
      "Epoch 33/50\n",
      "24/24 [==============================] - 23s 936ms/step - loss: 0.2480\n",
      "Epoch 34/50\n",
      "24/24 [==============================] - 23s 938ms/step - loss: 0.2383\n",
      "Epoch 35/50\n",
      "24/24 [==============================] - 23s 935ms/step - loss: 0.2281\n",
      "Epoch 36/50\n",
      "24/24 [==============================] - 22s 933ms/step - loss: 0.2196\n",
      "Epoch 37/50\n",
      "24/24 [==============================] - 23s 934ms/step - loss: 0.2112\n",
      "Epoch 38/50\n",
      "24/24 [==============================] - 23s 935ms/step - loss: 0.2088\n",
      "Epoch 39/50\n",
      "24/24 [==============================] - 23s 935ms/step - loss: 0.2049\n",
      "Epoch 40/50\n",
      "24/24 [==============================] - 22s 932ms/step - loss: 0.1976\n",
      "Epoch 41/50\n",
      "24/24 [==============================] - 23s 934ms/step - loss: 0.1947\n",
      "Epoch 42/50\n",
      "24/24 [==============================] - 23s 933ms/step - loss: 0.1881\n",
      "Epoch 43/50\n",
      "24/24 [==============================] - 22s 934ms/step - loss: 0.1861\n",
      "Epoch 44/50\n",
      "24/24 [==============================] - 22s 932ms/step - loss: 0.1824\n",
      "Epoch 45/50\n",
      "24/24 [==============================] - 22s 933ms/step - loss: 0.1809\n",
      "Epoch 46/50\n",
      "24/24 [==============================] - 23s 934ms/step - loss: 0.1777\n",
      "Epoch 47/50\n",
      "24/24 [==============================] - 22s 933ms/step - loss: 0.1738\n",
      "Epoch 48/50\n",
      "24/24 [==============================] - 21s 889ms/step - loss: 0.1719\n",
      "Epoch 49/50\n",
      "24/24 [==============================] - 21s 883ms/step - loss: 0.1701\n",
      "Epoch 50/50\n",
      "24/24 [==============================] - 23s 942ms/step - loss: 0.1658\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=50, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, temp, gen_chars):     \n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)  \n",
    "  text_generated = []\n",
    "  model.reset_states()\n",
    "  for i in range(gen_chars):\n",
    "    predictions = model(input_eval)      \n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "    predictions = predictions / temp\n",
    "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "    input_eval = tf.expand_dims([predicted_id], 0)\n",
    "    text_generated.append(idx2char[predicted_id])  \n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (1, None, 256)            14592     \n",
      "                                                                 \n",
      " gru_22 (GRU)                (1, None, 1024)           3938304   \n",
      "                                                                 \n",
      " gru_23 (GRU)                (1, None, 512)            2362368   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (1, None, 57)             29241     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,344,505\n",
      "Trainable params: 6,344,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                            batch_input_shape=[1, None]),\n",
    "  tf.keras.layers.GRU(rnn_units,\n",
    "                      return_sequences=True,\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform'),\n",
    "  tf.keras.layers.GRU(rnn_units_2,\n",
    "                      return_sequences=True,\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform'), \n",
    "  tf.keras.layers.Dense(vocab_size)\n",
    "])\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                            batch_input_shape=[1, None]),\n",
    "  tf.keras.layers.GRU(rnn_units,\n",
    "                      return_sequences=True,\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform'),\n",
    "  tf.keras.layers.GRU(rnn_units_2,\n",
    "                      return_sequences=True,\n",
    "                      stateful=True,\n",
    "                      recurrent_initializer='glorot_uniform'), \n",
    "  tf.keras.layers.Dense(vocab_size)\n",
    "])\n",
    "model.summary()\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice said to the Dormouse, in a shrill, passionate voice. Would\\ryou like cats if you were me\\r\\rWell, perhaps not, said the Mouse. I proceed. Edwin anxy direction, with a treelictures or conversations\\r\\rSo she wa'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, u\"Alice said\", 1.0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
